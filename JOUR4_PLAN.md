# ğŸ“… JOUR 4 : Scraper Zealy (API REST) - Plan DÃ©taillÃ©

## ğŸ¯ Objectif du Jour 4
AmÃ©liorer et optimiser le scraper Zealy existant, ajouter des tests unitaires, intÃ©grer avec le pipeline principal, et crÃ©er une version robuste pour la production.

## âœ… Ã‰tat Actuel (Acquis)
- âœ… Scraper Zealy fonctionnel (14 quÃªtes rÃ©cupÃ©rÃ©es)
- âœ… IntÃ©gration Vault opÃ©rationnelle 
- âœ… Parsing des donnÃ©es rÃ©ussi
- âœ… Format de sortie standardisÃ©

---

## ğŸ“‹ Plan DÃ©taillÃ© (2h30 = 5 crÃ©neaux Ã— 30 min)

### ğŸ• CrÃ©neau 1 (0:00-0:30) : Optimisation du Scraper Zealy
**Objectif** : AmÃ©liorer la robustesse et les performances

**TÃ¢ches** :
1. Ajouter la gestion des erreurs rÃ©seau (retry, timeout)
2. ImplÃ©menter le calcul du ROI automatique
3. Ajouter la validation des donnÃ©es d'entrÃ©e
4. Optimiser le parsing pour diffÃ©rents types de rewards

**Code Ã  implÃ©menter** :
```python
# Ajouter dans ZealyScraper
def calculate_roi(self, reward_amount, time_est_min, currency="XP"):
    """Calcul ROI en $/min"""
    # Conversion XP vers $ (exemple: 1 XP = $0.01)
    currency_rates = {"XP": 0.01, "POINTS": 0.005, "TOKENS": 1.0}
    usd_value = reward_amount * currency_rates.get(currency, 0.01)
    return usd_value / max(time_est_min, 1)  # Ã‰viter division par 0
```

### ğŸ• CrÃ©neau 2 (0:30-1:00) : Tests Unitaires
**Objectif** : CrÃ©er une suite de tests complÃ¨te

**TÃ¢ches** :
1. CrÃ©er `tests/test_zealy_scraper.py`
2. Tests pour l'authentification Vault
3. Tests pour le parsing de diffÃ©rents formats de rÃ©ponse
4. Tests pour le calcul du ROI
5. Mock des appels API

### ğŸ• CrÃ©neau 3 (1:00-1:30) : IntÃ©gration Multi-Sources
**Objectif** : Fusionner Galxe + Zealy dans un pipeline unique

**TÃ¢ches** :
1. Modifier `main.py` pour inclure les deux scrapers
2. Normaliser le format de sortie (schema commun)
3. DÃ©duplication inter-sources (hash MD5)
4. AgrÃ©gation des rÃ©sultats

### ğŸ• CrÃ©neau 4 (1:30-2:00) : Filtrage et ROI
**Objectif** : ImplÃ©menter le filtrage intelligent

**TÃ¢ches** :
1. CrÃ©er `processing/filters.py`
2. Filtrer ROI > $2/min
3. Filtrer par statut (actif, non expirÃ©)
4. Ranking par score composite (ROI Ã— facilitÃ©)

### ğŸ• CrÃ©neau 5 (2:00-2:30) : Stockage et Export
**Objectif** : Sauvegarder et exporter les rÃ©sultats

**TÃ¢ches** :
1. Export JSON horodatÃ©
2. Export CSV pour analyse
3. Statistiques du run (nombre d'opportunitÃ©s, ROI moyen)
4. Logs structurÃ©s

---

## ğŸ§ª Tests Ã  Valider

### âœ… Test 1 : Scraper Zealy Individual
```bash
python scrapers/zealy_scraper.py
# Attendu: "âœ… X quÃªtes parsÃ©es"
```

### âœ… Test 2 : Pipeline Complet
```bash
python main.py
# Attendu: AgrÃ©gation Galxe + Zealy
```

### âœ… Test 3 : Tests Unitaires
```bash
python -m pytest tests/test_zealy_scraper.py -v
# Attendu: Tous les tests passent
```

### âœ… Test 4 : Calcul ROI
```bash
# VÃ©rifier que les opportunitÃ©s sont triÃ©es par ROI dÃ©croissant
```

---

## ğŸ“Š Livrables Attendus

1. **scrapers/zealy_scraper.py** : Version optimisÃ©e avec ROI
2. **tests/test_zealy_scraper.py** : Suite de tests complÃ¨te
3. **processing/filters.py** : Module de filtrage
4. **main.py** : Pipeline consolidÃ© Galxe + Zealy
5. **data/opportunities_YYYYMMDD_HHMMSS.json** : Export horodatÃ©
6. **JOUR4_RAPPORT.md** : Rapport d'exÃ©cution

---

## ğŸ”§ Commandes ClÃ©s

```bash
# Activer l'environnement
venv\Scripts\activate

# Tester Zealy seul
python scrapers\zealy_scraper.py

# Tester pipeline complet
python main.py

# Lancer les tests
python -m pytest tests/ -v

# VÃ©rifier les donnÃ©es
dir data\
type data\opportunities_*.json
```

---

## ğŸ¯ CritÃ¨res de SuccÃ¨s

- [ ] Scraper Zealy robuste (gestion erreurs)
- [ ] Tests unitaires > 90% coverage
- [ ] Pipeline Galxe + Zealy fonctionnel
- [ ] Filtrage ROI > $2/min opÃ©rationnel
- [ ] Export de donnÃ©es structurÃ©es
- [ ] Documentation des API utilisÃ©es

---

## ğŸ”„ Prochaines Ã‰tapes (Jour 5)

1. Scraper Twitter/RSS
2. Module fallback (si API down)
3. Monitoring des quotas API
4. Cache des rÃ©sultats

## ğŸ“ Notes Techniques

- API Zealy: `https://api-v1.zealy.io/communities/aipioneers/quests`
- Limite: 20 quÃªtes/page, pagination disponible
- Headers: `x-api-key` requis
- Format: JSON avec structure `data[]` ou array direct
- ROI: CalculÃ© sur `reward/time_estimate` avec conversion currency
