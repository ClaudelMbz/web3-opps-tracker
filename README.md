# ğŸš€ Web3 Opportunities Tracker

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)

**SystÃ¨me automatisÃ© de dÃ©tection, filtrage et notification d'opportunitÃ©s Web3** (airdrops, bounties, quÃªtes) Ã  haut rendement.

## ğŸ“‹ Table des matiÃ¨res

- [ğŸ¯ Objectifs](#-objectifs)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [âš¡ Installation Rapide](#-installation-rapide)
- [ğŸ”§ Configuration](#-configuration)
- [ğŸš€ Utilisation](#-utilisation)
- [ğŸ“Š FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [ğŸ§ª Tests](#-tests)
- [ğŸ“ˆ Monitoring](#-monitoring)
- [ğŸ” SÃ©curitÃ©](#-sÃ©curitÃ©)
- [ğŸ¤ Contribution](#-contribution)

## ğŸ¯ Objectifs

- **200+ opportunitÃ©s/jour** : Scraping automatisÃ© multi-sources
- **ROI > $2/min** : Filtrage intelligent des opportunitÃ©s rentables
- **100% automatisÃ©** : Notifications Telegram instantanÃ©es
- **DurÃ©e de vie 6-12 mois** : Architecture Ã©volutive

## ğŸ—ï¸ Architecture

```
Web3-Opps-Tracker/
â”œâ”€â”€ ğŸ“ scrapers/           # Scrapers pour chaque plateforme
â”‚   â”œâ”€â”€ galxe_scraper.py   # API GraphQL Galxe
â”‚   â””â”€â”€ zealy_scraper.py   # API REST Zealy (âœ… ROI intÃ©grÃ©)
â”œâ”€â”€ ğŸ“ processing/         # Filtrage et traitement
â”œâ”€â”€ ğŸ“ monitoring/         # MÃ©triques et alertes
â”œâ”€â”€ ğŸ“ tests/             # Tests unitaires
â”œâ”€â”€ ğŸ³ docker-compose.yml # Infrastructure (Vault, Grafana)
â”œâ”€â”€ ğŸ” vault_manager.py   # Gestion sÃ©curisÃ©e des secrets
â””â”€â”€ âš™ï¸ main.py            # Pipeline principal
```

### ğŸ¢ Infrastructure

- **ğŸ” HashiCorp Vault** : Stockage sÃ©curisÃ© des clÃ©s API
- **ğŸ“Š Prometheus + Grafana** : Monitoring temps rÃ©el
- **ğŸ³ Docker** : Conteneurisation des services
- **ğŸ”„ n8n** : Orchestration des workflows

## âš¡ Installation Rapide

### 1. PrÃ©requis

```bash
# Windows
choco install docker-desktop git python
# Ou tÃ©lÃ©charger manuellement

# Linux/macOS
sudo apt install docker docker-compose git python3-pip
```

### 2. Installation

```bash
git clone https://github.com/ClaudelMbz/web3-opps-tracker.git
cd web3-opps-tracker

# Environnement virtuel
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/macOS

# DÃ©pendances
pip install -r requirements.txt
playwright install chromium
```

### 3. Services Docker

```bash
# Lancer Vault + Monitoring
docker network create web3-net
docker run -d --name vault --network web3-net -p 8200:8200 \
  -e VAULT_DEV_ROOT_TOKEN_ID="web3root" vault:latest
```

## ğŸ”§ Configuration

### 1. Variables d'environnement

CrÃ©er un fichier `.env` :

```env
# Vault
VAULT_ADDR=http://localhost:8200
VAULT_TOKEN=web3root

# API Keys (stockÃ©es dans Vault)
ZEALY_API_KEY=votre_cle_zealy
GALXE_API_KEY=votre_cle_galxe

# Telegram
BOT_TOKEN=votre_bot_token
MY_CHAT_ID=votre_chat_id
```

### 2. Configuration Vault

```bash
# Stocker les secrets
python vault_manager.py
```

## ğŸš€ Utilisation

### ğŸ¯ Scraping simple

```bash
# Tester Zealy
python scrapers/zealy_scraper.py

# Tester Galxe
python scrapers/galxe_scraper.py

# Pipeline complet
python main.py
```

### ğŸ“Š RÃ©sultats

Les opportunitÃ©s sont sauvegardÃ©es dans :
- `data/opportunities_YYYYMMDD.json`
- TriÃ©es par **ROI dÃ©croissant**
- FiltrÃ©es par seuil `ROI > $2/min`

## ğŸ“Š FonctionnalitÃ©s

### âœ… Scrapers Disponibles

| Plateforme | Status | ROI | Pagination | Notes |
|-----------|--------|-----|------------|-------|
| **Zealy** | âœ… OpÃ©rationnel | âœ… CalculÃ© | âœ… Auto | API REST stable |
| **Galxe** | âœ… OpÃ©rationnel | ğŸ”„ En cours | âœ… Auto | GraphQL + fallback |
| Twitter RSS | ğŸ”„ PrÃ©vu J5 | - | âœ… Auto | Fallback feeds |
| CryptoPanic | ğŸ”„ PrÃ©vu J5 | - | âœ… Auto | News filtering |

### ğŸ§® Calcul ROI

```python
# Conversion automatique des devises
currency_rates = {
    "XP": 0.01,      # 1 XP = $0.01
    "POINTS": 0.005, # 1 POINT = $0.005  
    "TOKENS": 1.0,   # 1 TOKEN = $1.00
    "GAL": 2.5,      # 1 GAL = $2.50
    "USD": 1.0       # 1 USD = $1.00
}

roi_usd_per_min = (reward Ã— rate) / time_estimate
```

### ğŸ“ˆ MÃ©triques Suivies

- **Volume** : OpportunitÃ©s/jour par source
- **QualitÃ©** : % ROI > seuil
- **Performance** : Latence API, taux d'erreur
- **RentabilitÃ©** : Gain estimÃ© vs coÃ»t infrastructure

## ğŸ§ª Tests

```bash
# Tests unitaires
python -m pytest tests/ -v

# Coverage
python -m pytest tests/ --cov=scrapers --cov-report=html

# Test d'intÃ©gration
python tests/integration_test.py
```

## ğŸ“ˆ Monitoring

### Dashboard Grafana
- **URL** : http://localhost:3000
- **Login** : admin/admin
- **MÃ©triques** : Latence, volume, erreurs

### Alertes Telegram
- Ã‰checs de scraping
- DÃ©passement de quotas
- OpportunitÃ©s > seuil ROI

## ğŸ” SÃ©curitÃ©

### ğŸ”‘ Gestion des Secrets

```bash
# Toutes les clÃ©s API sont dans Vault
vault kv get secret/zealy/api
vault kv get secret/galxe/api
```

### ğŸ›¡ï¸ Bonnes Pratiques

- âœ… Aucune clÃ© en plain-text dans le code
- âœ… .env exclu du versioning
- âœ… Chiffrement des tokens Vault
- âœ… Rotation pÃ©riodique des clÃ©s

## ğŸš§ Roadmap

### Phase Actuelle : **Jour 4/23** âœ…
- [x] Infrastructure (Vault, Docker, Git)
- [x] Scraper Zealy avec ROI
- [x] Scraper Galxe avec GraphQL
- [x] Tests unitaires
- [ ] Pipeline multi-sources
- [ ] Filtrage avancÃ©

### Prochaines Phases
- **J5-J8** : Twitter/RSS, Pipeline ETL, Google Sheets
- **J9-J12** : Dashboard Streamlit, n8n workflows  
- **J13-J15** : CI/CD, Documentation, Production
- **J16-J18** : NLP, Cache Redis, Optimisations

## ğŸ“Š Performance

### Benchmarks Actuels
- **Zealy** : 14 quÃªtes rÃ©cupÃ©rÃ©es en ~2s
- **Galxe** : Variable selon campagnes actives
- **MÃ©moire** : ~50MB par scraper
- **ROI moyen** : $0.01-$0.30/min selon sources

### Objectifs Production
- **DÃ©bit** : 200+ opp/jour consolidÃ©es
- **Latence** : \< 5min notification aprÃ¨s publication
- **DisponibilitÃ©** : 99.5% uptime
- **CoÃ»t** : \< $75/mois infrastructure

## ğŸ¤ Contribution

### DÃ©veloppement Local

```bash
# Fork le repo
git clone https://github.com/YOUR_USERNAME/web3-opps-tracker.git

# Branche feature
git checkout -b feature/nouveau-scraper

# Commits
git commit -m "âœ¨ Add Layer3 scraper with ROI"

# Tests avant push
python -m pytest tests/
python scrapers/new_scraper.py
```

### Ajout de Nouveaux Scrapers

1. HÃ©riter de `BaseScraper` dans `scrapers/`
2. ImplÃ©menter `fetch_data()` et `parse_data()`
3. Ajouter calcul ROI avec `calculate_roi()`
4. Tests unitaires dans `tests/`
5. Documentation dans README

## ğŸ“ Support

- **Issues** : [GitHub Issues](https://github.com/ClaudelMbz/web3-opps-tracker/issues)
- **Discussions** : [GitHub Discussions](https://github.com/ClaudelMbz/web3-opps-tracker/discussions)
- **Email** : claudelmubenzem90@gmail.com

## ğŸ“„ Licence

MIT License - voir [LICENSE](LICENSE) pour plus de dÃ©tails.

---

â­ **Star le repo si ce projet vous aide !** â­

**DÃ©veloppÃ© avec â¤ï¸ par [Claudel Mubenzem](https://github.com/ClaudelMbz)**
