#!/usr/bin/env python3
"""
Script de diagnostic pour analyser le contenu RSS et identifier 
pourquoi si peu d'opportunit√©s sont d√©tect√©es
"""

from scrapers.twitter_rss_scraper import TwitterRSSScraper
import json

def diagnostic_complet():
    print("üîç DIAGNOSTIC RSS COMPLET")
    print("=" * 60)
    
    scraper = TwitterRSSScraper()
    
    # 1. Test de connectivit√© d√©taill√©
    print("\n1Ô∏è‚É£ TEST DE CONNECTIVIT√â")
    scraper.test_connection()
    
    # 2. Analyse des entr√©es r√©cup√©r√©es
    print("\n2Ô∏è‚É£ ANALYSE DES ENTR√âES R√âCUP√âR√âES")
    
    # Flux principaux
    print("\nüì° Flux principaux:")
    rss_entries = scraper.fetch_opportunities(max_entries=10)
    print(f"Total r√©cup√©r√©: {len(rss_entries)} entr√©es")
    
    if rss_entries:
        print("\nüîç √âchantillon du contenu r√©cup√©r√©:")
        for i, entry in enumerate(rss_entries[:3], 1):
            print(f"\n--- Entr√©e {i} ---")
            print(f"Titre: {entry['title']}")
            print(f"R√©sum√©: {entry.get('summary', 'N/A')[:200]}...")
            print(f"Lien: {entry['link']}")
            print(f"Source: {entry['source_feed']}")
    
    # Fallbacks
    print("\nüîÑ Flux fallbacks:")
    fallback_entries = scraper.fetch_fallback_opportunities(max_entries=10)
    print(f"Total fallback: {len(fallback_entries)} entr√©es")
    
    if fallback_entries:
        print("\nüîç √âchantillon fallback:")
        for i, entry in enumerate(fallback_entries[:3], 1):
            print(f"\n--- Fallback {i} ---")
            print(f"Titre: {entry['title']}")
            print(f"R√©sum√©: {entry.get('summary', 'N/A')[:200]}...")
            print(f"Lien: {entry['link']}")
            print(f"Source: {entry['source_feed']}")
    
    # 3. Test de filtrage par mots-cl√©s
    print("\n3Ô∏è‚É£ ANALYSE DU FILTRAGE")
    all_entries = rss_entries + fallback_entries
    
    # Analyse des mots-cl√©s actuels
    current_keywords_main = ['airdrop', 'quest', 'task', 'reward', 'earn', 'free']
    current_keywords_fallback = ['airdrop', 'free', 'earn', 'reward', 'giveaway', 'claim']
    
    print(f"\nüîç Mots-cl√©s actuels (principaux): {current_keywords_main}")
    print(f"üîç Mots-cl√©s actuels (fallbacks): {current_keywords_fallback}")
    
    matched_main = 0
    matched_fallback = 0
    rejected_titles = []
    
    for entry in all_entries:
        title_lower = entry['title'].lower()
        is_fallback = entry.get('is_fallback', False)
        
        if is_fallback:
            keywords = current_keywords_fallback
            if any(keyword in title_lower for keyword in keywords):
                matched_fallback += 1
            else:
                rejected_titles.append((entry['title'], 'fallback'))
        else:
            keywords = current_keywords_main
            if any(keyword in title_lower for keyword in keywords):
                matched_main += 1
            else:
                rejected_titles.append((entry['title'], 'main'))
    
    print(f"\nüìä R√©sultats filtrage par mots-cl√©s:")
    print(f"   ‚úÖ Principales accept√©es: {matched_main}")
    print(f"   ‚úÖ Fallbacks accept√©es: {matched_fallback}")
    print(f"   ‚ùå Total rejet√©es: {len(rejected_titles)}")
    
    # 4. Analyse des titres rejet√©s
    print("\n4Ô∏è‚É£ TITRES REJET√âS (√©chantillon)")
    for i, (title, source_type) in enumerate(rejected_titles[:10]):
        print(f"   {i+1}. [{source_type}] {title[:80]}...")
    
    # 5. Test de d√©tection de langue
    print("\n5Ô∏è‚É£ TEST D√âTECTION DE LANGUE")
    english_count = 0
    non_english_count = 0
    
    for entry in all_entries[:20]:  # Test sur √©chantillon
        full_text = f"{entry['title']} {entry.get('summary', '')}"
        is_english = scraper.is_english_content(full_text)
        if is_english:
            english_count += 1
        else:
            non_english_count += 1
            print(f"   ‚ùå Non-anglais d√©tect√©: {entry['title'][:60]}...")
    
    print(f"\nüìä D√©tection langue (sur {english_count + non_english_count} √©chantillons):")
    print(f"   ‚úÖ Anglais: {english_count}")
    print(f"   ‚ùå Non-anglais: {non_english_count}")
    
    # 6. Recommandations
    print("\n6Ô∏è‚É£ RECOMMANDATIONS")
    
    total_entries = len(all_entries)
    total_matched = matched_main + matched_fallback
    
    if total_matched / total_entries < 0.2:  # Moins de 20% de correspondance
        print("üö® PROBL√àME MAJEUR: Filtrage trop strict!")
        print("   ‚Üí √âtendre la liste des mots-cl√©s")
        print("   ‚Üí Consid√©rer des termes crypto g√©n√©raux")
        
    if non_english_count > english_count:
        print("üö® PROBL√àME: D√©tection de langue trop stricte")
        print("   ‚Üí Ajuster les seuils de d√©tection")
        
    # 7. Suggestions d'am√©lioration
    print("\n7Ô∏è‚É£ MOTS-CL√âS SUGG√âR√âS")
    crypto_keywords = [
        'crypto', 'blockchain', 'defi', 'nft', 'token', 'coin',
        'testnet', 'mainnet', 'staking', 'yield', 'farming',
        'trading', 'swap', 'liquidity', 'bridge', 'layer2',
        'whitelist', 'presale', 'ido', 'ico', 'launch'
    ]
    print(f"   Mots-cl√©s crypto: {crypto_keywords}")
    
    opportunity_keywords = [
        'opportunity', 'campaign', 'event', 'competition',
        'contest', 'giveaway', 'bonus', 'incentive', 'program'
    ]
    print(f"   Mots-cl√©s opportunit√©s: {opportunity_keywords}")

if __name__ == "__main__":
    diagnostic_complet()
